
"""
Configuration for MILK10k Training
"""
data:
  dataset: "milk10k"
  train_data_dir: "data/milk10k/train"  # Ensure this structure is followed
  val_data_dir: "data/milk10k/val"      # Optional if validation split is handled differently
  img_size: 224
  batch_size: 32
  num_workers: 4
  classes:
    - AKIEC
    - BCC
    - BEN_OTH
    - BKL
    - DF
    - INF
    - MAL_OTH
    - MEL
    - NV
    - SCCKA
    - VASC

model:
  architecture: "tam_vit_base"
  num_classes: 11
  in_chans: 6        # Dual input: Clinical (3) + Dermoscopic (3)
  pretrained: true   # Start with ImageNet weights if possible (adapt first layer)

training:
  epochs: 50
  learning_rate: 1e-4
  weight_decay: 1e-4
  accumulate_grad_batches: 2
  gradient_clip_val: 1.0
  precision: 16-mixed

optimizer:
  name: "adamw"
  betas: [0.9, 0.999]

scheduler:
  name: "cosine_warmup"
  warmup_epochs: 5

loss:
  name: "focal"   # Handle class imbalance
  gamma: 2.0

logging:
  wandb:
    enabled: true
    project: "milk10k-challenge"
  log_every_n_steps: 10

paths:
  output_dir: "outputs/milk10k"
  checkpoint_dir: "outputs/milk10k/checkpoints"
  log_dir: "outputs/milk10k/logs"
